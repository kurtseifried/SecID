---
type: entity
namespace: paperpile.com
full_name: "Paperpile"
operator: "secid:entity/paperpile.com"
website: "https://paperpile.com"
status: active

sources:
  ai-risk-frameworks:
    full_name: "AI Risk Repository Frameworks Collection"
    urls:
      website: "https://paperpile.com/shared/AI-Risk-Repository-Frameworks-PUBLIC-t2cvtMee8TkuNni4tuDJSeQ"
---

# Paperpile

Paperpile is a reference management tool that allows sharing of curated bibliographies.

## Why Paperpile Matters for SecID

Paperpile shared libraries serve as curated collections of research that can help identify frameworks, taxonomies, and standards to add to the SecID registry.

---

## ai-risk-frameworks

A curated bibliography of 75+ AI risk frameworks, taxonomies, and research papers maintained as a shared Paperpile library.

### What It Is

A publicly shared Paperpile reference collection aggregating AI risk research including:
- Risk taxonomies and frameworks
- Incident analysis research
- Safety benchmarks and standards
- Governance frameworks
- Academic surveys and meta-analyses

### What It Contains

| Category | Examples |
|----------|----------|
| Risk Taxonomies | MIT AI Risk Repository sources, systemic risk taxonomies |
| Incident Analysis | Real-world GenAI incidents, misuse tactics |
| Harms Frameworks | Human-centered AI harm taxonomies |
| Standards | Frontier AI risk management, international safety reports |
| Benchmarks | AILuminate, safety evaluations |

### How to Use

The collection is viewable at the shared URL. Individual references link to their source publications (academic papers, reports, frameworks).

### Notes

- Contains 75+ curated references as of early 2025
- Organized into categorized collections (V1-V4)
- Useful for discovering AI risk resources to add to SecID registry
