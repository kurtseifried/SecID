---
type: entity
namespace: paperpile
name: ai-risk-frameworks
full_name: "AI Risk Repository Frameworks Collection"
operator: "secid:entity/paperpile"

urls:
  website: "https://paperpile.com/shared/AI-Risk-Repository-Frameworks-PUBLIC-t2cvtMee8TkuNni4tuDJSeQ"

status: active
---

# AI Risk Repository Frameworks (Paperpile)

A curated bibliography of 75+ AI risk frameworks, taxonomies, and research papers maintained as a shared Paperpile library.

## What It Is

A publicly shared Paperpile reference collection aggregating AI risk research including:
- Risk taxonomies and frameworks
- Incident analysis research
- Safety benchmarks and standards
- Governance frameworks
- Academic surveys and meta-analyses

## What It Contains

| Category | Examples |
|----------|----------|
| Risk Taxonomies | MIT AI Risk Repository sources, systemic risk taxonomies |
| Incident Analysis | Real-world GenAI incidents, misuse tactics |
| Harms Frameworks | Human-centered AI harm taxonomies |
| Standards | Frontier AI risk management, international safety reports |
| Benchmarks | AILuminate, safety evaluations |

## How to Use

The collection is viewable at the shared URL. Individual references link to their source publications (academic papers, reports, frameworks).

## Notes

- Contains 75+ curated references as of early 2025
- Organized into categorized collections (V1-V4)
- Useful for discovering AI risk resources to add to SecID registry
